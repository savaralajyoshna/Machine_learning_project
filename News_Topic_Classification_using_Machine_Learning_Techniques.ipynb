{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is called “Twenty Newsgroups”.\n",
        "In order to get faster execution times for this first example, we will work on a partial dataset with only 4 categories out of the 20 available in the dataset:"
      ],
      "metadata": {
        "id": "1Vtg9a6a00I2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_XmAXu1WPUJ"
      },
      "outputs": [],
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train',categories=categories, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now load the list of files matching those categories as follows:"
      ],
      "metadata": {
        "id": "xgKRbGZ50-lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAgxUdVAWq9x",
        "outputId": "00753552-9b81-4969-9ed8-7adc66e18a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(twenty_train.data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnsrsQjhWv8d",
        "outputId": "d65302da-fd30-42dd-ae21-2782fdb6c4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2257"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(twenty_train.filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGPBzkclWy49",
        "outputId": "59c58e0a-5785-449d-8897-5ec4c7103967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2257"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHpFECUNW3lc",
        "outputId": "6b3c5640-de1e-42a2-ca01-e839628d008e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: sd345@city.ac.uk (Michael Collier)\n",
            "Subject: Converting images to HP LaserJet III?\n",
            "Nntp-Posting-Host: hampton\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(twenty_train.target_names[twenty_train.target[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8KuFa2aW7W2",
        "outputId": "cb3d66df-bddf-4b51-bdc9-7dd5e3f8d80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train.target[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUt2_IdVW-CV",
        "outputId": "717b6e91-4077-4d44-be24-0b84a0484ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for t in twenty_train.target[:10]:\n",
        "    print(twenty_train.target_names[t])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZEVUq-5XDj1",
        "outputId": "14b7b91f-f61e-4569-96f5-f0c6bd2b879f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "comp.graphics\n",
            "comp.graphics\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "soc.religion.christian\n",
            "sci.med\n",
            "sci.med\n",
            "sci.med\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text preprocessing, tokenizing and filtering of stopwords are all included in CountVectorizer, which builds a dictionary of features and transforms documents to feature vectors:"
      ],
      "metadata": {
        "id": "batbyLEg1Mal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dnigvmdXHT0",
        "outputId": "0396c24d-a2a9-48de-c8a4-24058e39cddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer supports counts of N-grams of words or consecutive characters. Once fitted, the vectorizer has built a dictionary of feature indices:"
      ],
      "metadata": {
        "id": "psFy58fw1Rmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vect.vocabulary_.get(u'algorithm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQoBagGuXKD1",
        "outputId": "ccdc7d7f-33dc-4e5b-b8bb-526e9fabfeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4690"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
        "X_train_tf = tf_transformer.transform(X_train_counts)\n",
        "X_train_tf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5HNC5UUXM3A",
        "outputId": "27f96f4d-d12d-4bc5-802f-6d523fbe9fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKps_igSXYDf",
        "outputId": "5000ed30-d29b-4f93-f38f-f257c989c4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2257, 35788)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training a classifier**"
      ],
      "metadata": {
        "id": "5xnF9sBn1kZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "metadata": {
        "id": "fpxpze8iXbnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
        "X_new_counts = count_vect.transform(docs_new)\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "\n",
        "predicted = clf.predict(X_new_tfidf)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "    print('%r => %s' % (doc, twenty_train.target_names[category]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgAzIHj_XfBy",
        "outputId": "a29b02a5-2908-4c3d-c20d-ff79c96cd623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'God is love' => soc.religion.christian\n",
            "'OpenGL on the GPU is fast' => comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building a pipeline**"
      ],
      "metadata": {
        "id": "GP4PP3IO1tf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', MultinomialNB()),\n",
        "])"
      ],
      "metadata": {
        "id": "HZ9Y97oqXij3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "T3R7B0uhXmk_",
        "outputId": "17cb73de-e8b3-4ab6-c37b-56a6a0f4c9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
              "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation of the performance on the test set**"
      ],
      "metadata": {
        "id": "q-aWFysH1zMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test',\n",
        "    categories=categories, shuffle=True, random_state=42)\n",
        "docs_test = twenty_test.data\n",
        "predicted = text_clf.predict(docs_test)\n",
        "np.mean(predicted == twenty_test.target)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIPkaz6pXqkg",
        "outputId": "27dff5fd-66a9-4b9b-a6f7-d74c5cb782c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8348868175765646"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf = Pipeline([\n",
        "    ('vect', CountVectorizer()),\n",
        "    ('tfidf', TfidfTransformer()),\n",
        "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
        "                          alpha=1e-3, random_state=42,\n",
        "                          max_iter=5, tol=None)),\n",
        "])\n",
        "\n",
        "text_clf.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "predicted = text_clf.predict(docs_test)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QtStE8DXuQ5",
        "outputId": "9342cf18-3bc6-43c4-d121-95627b3a87a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9101198402130493"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(twenty_test.target, predicted,\n",
        "    target_names=twenty_test.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQXoj9LbXxwV",
        "outputId": "cf8ae783-b4ed-4be0-8e16-72acb471bdc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "           alt.atheism       0.95      0.80      0.87       319\n",
            "         comp.graphics       0.87      0.98      0.92       389\n",
            "               sci.med       0.94      0.89      0.91       396\n",
            "soc.religion.christian       0.90      0.95      0.93       398\n",
            "\n",
            "              accuracy                           0.91      1502\n",
            "             macro avg       0.91      0.91      0.91      1502\n",
            "          weighted avg       0.91      0.91      0.91      1502\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.confusion_matrix(twenty_test.target, predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8B9yLBxX0bQ",
        "outputId": "25be01ca-1fe1-4e72-c6be-6dd2f40a6cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[256,  11,  16,  36],\n",
              "       [  4, 380,   3,   2],\n",
              "       [  5,  35, 353,   3],\n",
              "       [  5,  11,   4, 378]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameter tuning using grid search**"
      ],
      "metadata": {
        "id": "5q2v3Qal2D1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {\n",
        "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'clf__alpha': (1e-2, 1e-3),\n",
        "}"
      ],
      "metadata": {
        "id": "cvBf2lkLX3WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
      ],
      "metadata": {
        "id": "5_Ph5Fa6X9Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
      ],
      "metadata": {
        "id": "HegaJHVmX_6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "E8V3PeJeYFxQ",
        "outputId": "6fe96cef-b5bd-4e4f-baff-a4514cd21163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'soc.religion.christian'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf.best_score_\n",
        "\n",
        "for param_name in sorted(parameters.keys()):\n",
        "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9F-tRJCYJ6R",
        "outputId": "ba6abc1f-9236-4481-f5ee-43360f0b357c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clf__alpha: 0.001\n",
            "tfidf__use_idf: True\n",
            "vect__ngram_range: (1, 1)\n"
          ]
        }
      ]
    }
  ]
}